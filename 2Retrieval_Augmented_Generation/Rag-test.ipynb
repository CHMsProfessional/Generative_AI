{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Dependencies (already in your code)\n",
    "import os\n",
    "import pinecone\n",
    "import openai\n",
    "#import logging\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone as PineconeVectorStore\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.vectorstores import Pinecone as PineconeVectorStore\n",
    "from langchain.chat_models import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Read Pinecone and Azure OpenAI Environment Variables\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"BjSM1Dwo5UZVvPUizHw8w0n8i7TM3fHIK3GjbeIYX5Z1nqffyiCBJQQJ99BBACYeBjFXJ3w3AAABACOGRhVh\"\n",
    "os.environ[\"AZURE_OPENAI_API_BASE\"] = \"https://khipus-aoai.openai.azure.com\"\n",
    "os.environ[\"AZURE_OPENAI_DEPLOYMENT\"] = \"text-embedding-ada-002\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "\n",
    "openai.api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "openai.api_base = os.environ[\"AZURE_OPENAI_API_BASE\"]\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "\n",
    "#os.environ[\"PINECONE_API_KEY\"] = \"pcsk_56sL2K_6uS61piqrBjZkoCem53GXgvmUDvZTajV59k1gUKxJitiHqTUPi5ho5m1WThbh6x\"\n",
    "#os.environ[\"PINECONE_ENV\"] = \"us-east-1-aws\"  # Change as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 23 document(s) and split into 78 chunks.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Load your PDF and split into chunks\n",
    "pdf_path = \"./docs/corollacross_brochure.pdf\"  # Adjust the file path if needed\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "print(f\"Loaded {len(documents)} document(s) and split into {len(docs)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Initialize the Azure OpenAI embeddings object using LangChain.\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    openai_api_key=openai.api_key,\n",
    "    azure_endpoint=openai.api_base,  # Use azure_endpoint instead of openai_api_base\n",
    "    openai_api_version=openai.api_version,\n",
    "    deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available indexes: ['example-index', 'langchain-demo']\n",
      "Index 'langchain-demo' already exists.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 5: Generate embeddings for each chunk\n",
    "pinecone.Index = pinecone.data.index.Index\n",
    "\n",
    "# Replace these values as needed\n",
    "api_key = \"pcsk_56sL2K_6uS61piqrBjZkoCem53GXgvmUDvZTajV59k1gUKxJitiHqTUPi5ho5m1WThbh6x\" # Pinecone API key\n",
    "index_name = \"langchain-demo\"\n",
    "\n",
    "# Create an instance of the Pinecone class using the new API\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "# List indexes to check connectivity\n",
    "print(\"Available indexes:\", pc.list_indexes().names())\n",
    "\n",
    "# Create (or connect to) your Pinecone index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # Must match the embedding dimension\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"  # Ensure this matches your Pinecone dashboard\n",
    "        )\n",
    "    )\n",
    "    print(f\"Created index: {index_name}\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanikj\\AppData\\Local\\Temp\\ipykernel_28016\\3052846429.py:6: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.18 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-pinecone package and should be used instead. To use it run `pip install -U :class:`~langchain-pinecone` and import as `from :class:`~langchain_pinecone import Pinecone``.\n",
      "  vector_store = PineconeVectorStore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings have been successfully stored in Pinecone!\n"
     ]
    }
   ],
   "source": [
    "# Step 6 Create and store embeddings using the PineconeVectorStore\n",
    "# Retrieve the index client\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Create and store embeddings using the PineconeVectorStore\n",
    "vector_store = PineconeVectorStore(\n",
    "    index,         # The instance of pinecone.Index\n",
    "    embeddings,    # Your initialized embeddings object (Azure OpenAI embeddings)\n",
    "    text_key=\"text\",  # Adjust if your documents use a different key\n",
    "    namespace=\"default\"\n",
    ")\n",
    "\n",
    "# Assuming 'docs' contains your document chunks\n",
    "vector_store.add_documents(docs)\n",
    "\n",
    "print(\"Embeddings have been successfully stored in Pinecone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\temp\\building-qa-app-with-openai-pinecone-and-streamlit\\venvrag\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:174: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://khipus-aoai.openai.azure.com to https://khipus-aoai.openai.azure.com/openai.\n",
      "  warnings.warn(\n",
      "c:\\temp\\building-qa-app-with-openai-pinecone-and-streamlit\\venvrag\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:181: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "c:\\temp\\building-qa-app-with-openai-pinecone-and-streamlit\\venvrag\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:189: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://khipus-aoai.openai.azure.com to https://khipus-aoai.openai.azure.com/openai.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: {'creationdate': '2024-01-17T14:56:22-05:00', 'creator': 'Adobe InDesign 18.5 (Macintosh)', 'moddate': '2024-01-17T14:57:41-05:00', 'page': 2.0, 'page_label': '3', 'producer': 'Adobe PDF Library 17.0', 'source': './docs/corollacross_brochure.pdf', 'total_pages': 23.0, 'trapped': '/False'}\n",
      "Metadata: {'creationdate': '2024-01-17T14:56:22-05:00', 'creator': 'Adobe InDesign 18.5 (Macintosh)', 'moddate': '2024-01-17T14:57:41-05:00', 'page': 2.0, 'page_label': '3', 'producer': 'Adobe PDF Library 17.0', 'source': './docs/corollacross_brochure.pdf', 'total_pages': 23.0, 'trapped': '/False'}\n",
      "Metadata: {'creationdate': '2024-01-17T14:56:22-05:00', 'creator': 'Adobe InDesign 18.5 (Macintosh)', 'moddate': '2024-01-17T14:57:41-05:00', 'page': 2.0, 'page_label': '3', 'producer': 'Adobe PDF Library 17.0', 'source': './docs/corollacross_brochure.pdf', 'total_pages': 23.0, 'trapped': '/False'}\n",
      "Metadata: {'creationdate': '2024-01-17T14:56:22-05:00', 'creator': 'Adobe InDesign 18.5 (Macintosh)', 'moddate': '2024-01-17T14:57:41-05:00', 'page': 2.0, 'page_label': '3', 'producer': 'Adobe PDF Library 17.0', 'source': './docs/corollacross_brochure.pdf', 'total_pages': 23.0, 'trapped': '/False'}\n",
      "Answer: \n",
      "\n",
      "The Toyota Corolla Cross features a 2.0-liter engine.\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "# Initialize the language model using Azure Chat OpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_base=os.environ[\"AZURE_OPENAI_API_BASE\"],\n",
    "    openai_api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    openai_api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-10-21\"),\n",
    "    deployment_name=os.environ.get(\"AZURE_OPENAI_GPT4_MODEL_NAME\", \"gpt-4o\")\n",
    ")\n",
    "\n",
    "# Load the QA chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "# Define your query\n",
    "query = \"What is the engine size of the Toyota Corolla Cross?\"\n",
    "#What is the estimated fuel efficiency of the Corolla Cross Hybrid?\n",
    "\n",
    "# Retrieve similar documents from the vector store (removed include_metadata)\n",
    "docs = vector_store.similarity_search(query)\n",
    "\n",
    "# Optionally, access metadata from the documents if needed\n",
    "for doc in docs:\n",
    "    print(\"Metadata:\", doc.metadata)\n",
    "\n",
    "# Get the answer from the chain\n",
    "result = chain.run(input_documents=docs, question=query)\n",
    "\n",
    "print(f\"Answer: \\n\\n{result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
