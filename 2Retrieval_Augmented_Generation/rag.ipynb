{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from azure.cosmos import CosmosClient\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cosmos DB Setup ---\n",
    "url = os.getenv('COSMOS_DB_URL', 'https://khipus-rag.documents.azure.com:443/')\n",
    "key = os.getenv('COSMOS_DB_KEY', 'aHWuWA59JMIb7Z0giUhvbQSmzQgv9ETtg67razBKjXur8xi4XmETe45gY2hsIJnNNsXMKjKOYRG5ACDbq6xFbg==')\n",
    "client = CosmosClient(url, credential=key)\n",
    "database_name = 'rag-cosmos-db'\n",
    "database = client.get_database_client(database_name)\n",
    "container_name = 'data'\n",
    "container = database.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- DataFrame Creation ---\n",
    "df = pd.DataFrame(columns=['path', 'text'])\n",
    "data_paths = [\n",
    "    \"data/frameworks.md?WT.mc_id=academic-105485-koreyst\", \n",
    "    \"data/own_framework.md?WT.mc_id=academic-105485-koreyst\", \n",
    "    \"data/perceptron.md?WT.mc_id=academic-105485-koreyst\"\n",
    "]\n",
    "for path in data_paths:\n",
    "    actual_path = path.split('?')[0]\n",
    "    with open(actual_path, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.read()\n",
    "    df.loc[len(df)] = [actual_path, file_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Text Splitting ---\n",
    "def split_text(text, max_length, min_length):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    for word in words:\n",
    "        current_chunk.append(word)\n",
    "        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = []\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "splitted_df = df.copy()\n",
    "splitted_df['chunks'] = splitted_df['text'].apply(lambda x: split_text(x, 400, 300))\n",
    "flattened_df = splitted_df.explode('chunks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Azure OpenAI Configuration ---\n",
    "openai.api_type = \"azure\"\n",
    "# Set the API base to your Azure OpenAI resource endpoint (do not include deployment paths here)\n",
    "openai.api_base = \"https://khipus-aoai.openai.azure.com\"\n",
    "openai.api_version = \"2024-08-01-preview\"\n",
    "# Set your API key; ideally use an environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"BjSM1Dwo5UZVvPUizHw8w0n8i7TM3fHIK3GjbeIYX5Z1nqffyiCBJQQJ99BBACYeBjFXJ3w3AAABACOGRhVh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to Create Embeddings ---\n",
    "def create_embeddings(text, model=\"text-embedding-ada-002\"):\n",
    "    # When using Azure OpenAI, specify the deployment name using 'engine'\n",
    "    embeddings = openai.Embedding.create(input=[text], engine=model).data[0].embedding\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Compute and Store Embeddings ---\n",
    "flattened_df['embeddings'] = flattened_df['chunks'].apply(create_embeddings)\n",
    "embeddings_list = flattened_df['embeddings'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build Nearest Neighbors Index ---\n",
    "nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings_list)\n",
    "distances, indices = nbrs.kneighbors(embeddings_list)\n",
    "flattened_df['indices'] = indices.tolist()\n",
    "flattened_df['distances'] = distances.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Chatbot Function ---\n",
    "def chatbot(user_input):\n",
    "    # Convert the question to a query vector\n",
    "    query_vector = create_embeddings(user_input)\n",
    "    # Retrieve similar document chunks (for context)\n",
    "    _, indices = nbrs.kneighbors([query_vector])\n",
    "    history = [flattened_df['chunks'].iloc[i] for i in indices[0]]\n",
    "    # Optionally, add the user's question at the end of the history\n",
    "    history.append(user_input)\n",
    "    \n",
    "    # For the chat prompt, you can decide how much context to provide.\n",
    "    # Here we pass the last chunk as the user message.\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant that helps with AI questions.\"},\n",
    "        {\"role\": \"user\", \"content\": history[-1]}\n",
    "    ]    \n",
    "    # Create the chat completion request.\n",
    "    # Note: Use the 'engine' parameter to specify your deployment name (\"gpt-4o-mini\").\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"gpt-4o-mini\",  # Your deployment name in Azure OpenAI\n",
    "        temperature=0.7,\n",
    "        max_tokens=800,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example Usage ---\n",
    "user_input = \"what is a perceptron?\"\n",
    "response_message = chatbot(user_input)\n",
    "print(response_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
